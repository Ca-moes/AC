{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d385e443-1054-4c76-9e97-28f0350b4b94",
   "metadata": {},
   "source": [
    "# Parameter Tuning\n",
    "\n",
    "Exhaustive search over specified parameter values for an estimator, tuning the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b22a74f8-0528-4d01-af74-ee77dbbe333f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d808e6f3-c16a-4e7f-a551-301f8f963dbe",
   "metadata": {},
   "source": [
    "Getting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0befccd4-978e-4724-8dc1-b0e9b2d0ca19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Split\n",
    "train_data = pd.read_pickle(\"train_data.pkl\")\n",
    "test_data = pd.read_pickle(\"test_data.pkl\")\n",
    "\n",
    "features = list(train_data.columns)\n",
    "features.remove('status')\n",
    "features.remove('loan_id')\n",
    "\n",
    "x = train_data[features]\n",
    "y = train_data['status']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=0)\n",
    "\n",
    "# Resampling - Smote\n",
    "smote = SMOTE()\n",
    "x_train, y_train = smote.fit_resample(x_train, y_train)\n",
    "\n",
    "# Normalizing data\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(x_train)\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb43e278-29e0-496d-93ee-7f3a1f6f90be",
   "metadata": {},
   "source": [
    "Applying grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24e3515f-0b95-4150-85c9-ecbdc9ecb96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(model, parameter_grid):\n",
    "    grid_search = GridSearchCV(model,\n",
    "                               param_grid=parameter_grid,\n",
    "                               scoring='roc_auc',\n",
    "                               cv=5,\n",
    "                               verbose=4,\n",
    "                               n_jobs=-1)\n",
    "\n",
    "    grid_search.fit(x_train, y_train)\n",
    "\n",
    "    print(f\"\\nBest score: {grid_search.best_score_}\")\n",
    "    print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "    print(f\"Best estimator: {grid_search.best_estimator_}\")\n",
    "    \n",
    "    best_model = model = grid_search.best_estimator_\n",
    "    best_model_pred = best_model.predict(x_test)\n",
    "    best_model_pred_proba = best_model.predict_proba(x_test)[:, -1]\n",
    "\n",
    "    # Metrics\n",
    "    print(\"\\nAUC Score: \", metrics.roc_auc_score(y_test, best_model_pred_proba))\n",
    "    print(f\"Confusion matrix:\\n{metrics.confusion_matrix(y_test, best_model_pred)}\\n\")\n",
    "    print(f\"Classification report:\\n{metrics.classification_report(y_test, best_model_pred)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23ed17f-770c-4036-a0db-cc3b51331118",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5ae38d3-14ed-4024-bc37-b529b19eb989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1024 candidates, totalling 5120 fits\n",
      "\n",
      "Best score: 0.9134878369493753\n",
      "Best parameters: {'class_weight': None, 'criterion': 'entropy', 'max_features': 'sqrt', 'min_impurity_split': 0.05, 'min_samples_leaf': 2, 'min_samples_split': 8, 'splitter': 'best'}\n",
      "Best estimator: DecisionTreeClassifier(criterion='entropy', max_features='sqrt',\n",
      "                       min_impurity_split=0.05, min_samples_leaf=2,\n",
      "                       min_samples_split=8, random_state=0)\n",
      "\n",
      "AUC Score:  0.653361344537815\n",
      "Confusion matrix:\n",
      "[[12  2]\n",
      " [49 36]]\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.86      0.32        14\n",
      "           1       0.95      0.42      0.59        85\n",
      "\n",
      "    accuracy                           0.48        99\n",
      "   macro avg       0.57      0.64      0.45        99\n",
      "weighted avg       0.84      0.48      0.55        99\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fmna\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:315: FutureWarning: The min_impurity_split parameter is deprecated. Its default value has changed from 1e-7 to 0 in version 0.23, and it will be removed in 1.0 (renaming of 0.25). Use the min_impurity_decrease parameter instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "parameter_grid = {'criterion': ['gini', 'entropy'],\n",
    "            'splitter': ['best', 'random'],\n",
    "            'max_features': ['sqrt', 'log2'],\n",
    "            'min_samples_split':  [2, 4, 6, 8],\n",
    "            'min_samples_leaf':  [1, 2, 4, 6],\n",
    "            'min_impurity_split': [0.05, 0.1, 0.23, 0.3],\n",
    "            'class_weight': [\"balanced\", None]}\n",
    "\n",
    "grid_search(model, parameter_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280fd101-1eb2-4668-a0c5-e27a0a9baf01",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbd440dc-b90e-4bb9-8923-b579a531bdfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      "\n",
      "Best score: 0.9928550295857989\n",
      "Best parameters: {'criterion': 'entropy', 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 1500}\n",
      "Best estimator: RandomForestClassifier(criterion='entropy', n_estimators=1500, random_state=0)\n",
      "\n",
      "AUC Score:  0.773109243697479\n",
      "Confusion matrix:\n",
      "[[ 9  5]\n",
      " [25 60]]\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.64      0.37        14\n",
      "           1       0.92      0.71      0.80        85\n",
      "\n",
      "    accuracy                           0.70        99\n",
      "   macro avg       0.59      0.67      0.59        99\n",
      "weighted avg       0.83      0.70      0.74        99\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(random_state=0)\n",
    "\n",
    "parameter_grid = {'n_estimators': [1000, 1500, 1800, 2000],\n",
    "                  'criterion': ['gini', 'entropy'],\n",
    "                  'min_samples_split': [2, 5, 10],\n",
    "                  'min_samples_leaf': [1, 2, 4],\n",
    "                  'max_features': ['auto', None]}\n",
    "\n",
    "grid_search(model, parameter_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6550df1a-a43e-45c5-aa6f-55ec7999ce75",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd5d1429-156d-4fc8-9784-c0740c4b59f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "\n",
      "Best score: 0.951387245233399\n",
      "Best parameters: {'algorithm': 'ball_tree', 'n_neighbors': 10, 'weights': 'distance'}\n",
      "Best estimator: KNeighborsClassifier(algorithm='ball_tree', n_neighbors=10, weights='distance')\n",
      "\n",
      "AUC Score:  0.765546218487395\n",
      "Confusion matrix:\n",
      "[[13  1]\n",
      " [43 42]]\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.93      0.37        14\n",
      "           1       0.98      0.49      0.66        85\n",
      "\n",
      "    accuracy                           0.56        99\n",
      "   macro avg       0.60      0.71      0.51        99\n",
      "weighted avg       0.87      0.56      0.62        99\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = KNeighborsClassifier()\n",
    "\n",
    "parameter_grid = {'n_neighbors': [5, 10, 15],\n",
    "                  'weights': ['uniform', 'distance'],\n",
    "                  'algorithm': ['ball_tree', 'kd_tree', 'brute']}\n",
    "\n",
    "grid_search(model, parameter_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35201d2-51af-4e89-a0b3-1b16820cb937",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e8f1f62-6604-4dd8-ad89-6c73dc001ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
      "\n",
      "Best score: 0.992396449704142\n",
      "Best parameters: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Best estimator: SVC(C=10, probability=True, random_state=0)\n",
      "\n",
      "AUC Score:  0.807563025210084\n",
      "Confusion matrix:\n",
      "[[ 9  5]\n",
      " [17 68]]\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.64      0.45        14\n",
      "           1       0.93      0.80      0.86        85\n",
      "\n",
      "    accuracy                           0.78        99\n",
      "   macro avg       0.64      0.72      0.66        99\n",
      "weighted avg       0.85      0.78      0.80        99\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = SVC(random_state=0, probability=True)\n",
    "\n",
    "parameter_grid = {'C': [0.1, 1, 10, 100],\n",
    "              'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "              'gamma': ['scale', 'auto']}\n",
    "\n",
    "grid_search(model, parameter_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9a3a04-3449-473d-9d6c-b802bbb1c0de",
   "metadata": {},
   "source": [
    "## AdaBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0ccbcf0-e49f-409d-967e-ec7683553941",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "\n",
      "Best score: 0.9602564102564102\n",
      "Best parameters: {'learning_rate': 0.3, 'n_estimators': 100}\n",
      "Best estimator: AdaBoostClassifier(learning_rate=0.3, n_estimators=100, random_state=0)\n",
      "\n",
      "AUC Score:  0.7294117647058824\n",
      "Confusion matrix:\n",
      "[[10  4]\n",
      " [36 49]]\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.71      0.33        14\n",
      "           1       0.92      0.58      0.71        85\n",
      "\n",
      "    accuracy                           0.60        99\n",
      "   macro avg       0.57      0.65      0.52        99\n",
      "weighted avg       0.82      0.60      0.66        99\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = AdaBoostClassifier(random_state=0)\n",
    "\n",
    "parameter_grid = {'n_estimators': [50, 100, 150],\n",
    "                  'learning_rate': [0.3, 0.5, 1.0]}\n",
    "\n",
    "grid_search(model, parameter_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ff7630-42d1-4d0b-a012-91dfba3e9eee",
   "metadata": {},
   "source": [
    "## GradientBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d976512-6e2c-4b1f-bfcb-a25308f3c37e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 432 candidates, totalling 2160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fmna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.98751808 0.98816239 0.98737673 0.98314267 0.98468771 0.98660421\n",
      " 0.98313609 0.98659435 0.98544379 0.98389546 0.98478304 0.9851545\n",
      " 0.98465812 0.98983563 0.98945759 0.9830046  0.9858284  0.9866075\n",
      " 0.98344181 0.98705128 0.98755424 0.98344181 0.98705128 0.98755424\n",
      " 0.98394806 0.9881854  0.98690007 0.98751808 0.98816239 0.98737673\n",
      " 0.98314267 0.98468771 0.98660421 0.98313609 0.98659435 0.98544379\n",
      " 0.98389546 0.98478304 0.9851545  0.98465812 0.98983563 0.98945759\n",
      " 0.9830046  0.9858284  0.9866075  0.98344181 0.98705128 0.98755424\n",
      " 0.98344181 0.98705128 0.98755424 0.98394806 0.9881854  0.98690007\n",
      " 0.98496384 0.98673241 0.98672255 0.98352071 0.98609139 0.98610454\n",
      " 0.98110454 0.98505588 0.98633794 0.99010191 0.98920447 0.98817554\n",
      " 0.98741289 0.9898455  0.99061473 0.98508876 0.9868902  0.98688692\n",
      " 0.98279093 0.98703813 0.98716634 0.98279093 0.98703813 0.98716634\n",
      " 0.98742275 0.98728139 0.98791913 0.98496384 0.98673241 0.98672255\n",
      " 0.98352071 0.98609139 0.98610454 0.98110454 0.98505588 0.98633794\n",
      " 0.99010191 0.98920447 0.98817554 0.98741289 0.9898455  0.99061473\n",
      " 0.98508876 0.9868902  0.98688692 0.98279093 0.98703813 0.98716634\n",
      " 0.98279093 0.98703813 0.98716634 0.98742275 0.98728139 0.98791913\n",
      " 0.98431295 0.98533202 0.98624589 0.98521696 0.98675214 0.98597633\n",
      " 0.98301118 0.98455293 0.98455293 0.9822551  0.98455621 0.9857265\n",
      " 0.98394149 0.98713346 0.98867193 0.97917817 0.98109139 0.98454635\n",
      " 0.9830572  0.98639711 0.98754767 0.9830572  0.98639711 0.98754767\n",
      " 0.98278435 0.98715648 0.98485207 0.98431295 0.98533202 0.98624589\n",
      " 0.98521696 0.98675214 0.98597633 0.98301118 0.98455293 0.98455293\n",
      " 0.9822551  0.98455621 0.9857265  0.98394149 0.98713346 0.98867193\n",
      " 0.97917817 0.98109139 0.98454635 0.9830572  0.98639711 0.98754767\n",
      " 0.9830572  0.98639711 0.98754767 0.98278435 0.98715648 0.98485207\n",
      " 0.97876397 0.9851808  0.98466469 0.97438856 0.9799211  0.98237015\n",
      " 0.97618343 0.98314596 0.98315582 0.98071663 0.98238001 0.98455293\n",
      " 0.97352728 0.97992768 0.98146614 0.97223208 0.97941815 0.98160421\n",
      " 0.98164694 0.983833   0.98459895 0.98164694 0.983833   0.98459895\n",
      " 0.98421105 0.98883958 0.98690993 0.97876397 0.9851808  0.98466469\n",
      " 0.97438856 0.9799211  0.98237015 0.97618343 0.98314596 0.98315582\n",
      " 0.98071663 0.98238001 0.98455293 0.97352728 0.97992768 0.98146614\n",
      " 0.97223208 0.97941815 0.98160421 0.98164694 0.983833   0.98459895\n",
      " 0.98164694 0.983833   0.98459895 0.98421105 0.98883958 0.98690993\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best score: 0.9906147271531888\n",
      "Best parameters: {'criterion': 'friedman_mse', 'learning_rate': 0.3, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 150}\n",
      "Best estimator: GradientBoostingClassifier(learning_rate=0.3, max_features='auto',\n",
      "                           min_samples_leaf=2, min_samples_split=5,\n",
      "                           n_estimators=150, random_state=0)\n",
      "\n",
      "AUC Score:  0.7739495798319328\n",
      "Confusion matrix:\n",
      "[[12  2]\n",
      " [44 41]]\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.86      0.34        14\n",
      "           1       0.95      0.48      0.64        85\n",
      "\n",
      "    accuracy                           0.54        99\n",
      "   macro avg       0.58      0.67      0.49        99\n",
      "weighted avg       0.85      0.54      0.60        99\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = GradientBoostingClassifier(random_state=0)\n",
    "\n",
    "parameter_grid = {'n_estimators': [50, 100, 150],\n",
    "                  'learning_rate': [0.2, 0.3, 0.5, 1.0],\n",
    "                  'criterion': ['friedman_mse', 'squared_error'],\n",
    "                  'min_samples_split': [2, 5, 10],\n",
    "                  'min_samples_leaf': [1, 2, 4],\n",
    "                  'max_features': ['auto', None]}\n",
    "\n",
    "grid_search(model, parameter_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0172aa14-3812-4471-a95c-5d7f830b2b2b",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6919ebb-6696-404d-bcc3-5c9ce409e12e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "\n",
      "Best score: 0.9869230769230768\n",
      "Best parameters: {'alpha': 0.01, 'gamma': 0.01, 'learning_rate': 0.2, 'n_estimators': 200}\n",
      "Best estimator: XGBClassifier(alpha=0.01, base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, eval_metric='auc',\n",
      "              gamma=0.01, gpu_id=-1, importance_type='gain',\n",
      "              interaction_constraints='', learning_rate=0.2, max_delta_step=0,\n",
      "              max_depth=6, min_child_weight=1, missing=nan,\n",
      "              monotone_constraints='()', n_estimators=200, n_jobs=12,\n",
      "              num_parallel_tree=1, random_state=0, reg_alpha=0.00999999978,\n",
      "              reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "              tree_method='exact', use_label_encoder=False,\n",
      "              validate_parameters=1, verbosity=None)\n",
      "\n",
      "AUC Score:  0.8067226890756303\n",
      "Confusion matrix:\n",
      "[[11  3]\n",
      " [35 50]]\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.79      0.37        14\n",
      "           1       0.94      0.59      0.72        85\n",
      "\n",
      "    accuracy                           0.62        99\n",
      "   macro avg       0.59      0.69      0.55        99\n",
      "weighted avg       0.84      0.62      0.67        99\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier(objective='binary:logistic', use_label_encoder=False, eval_metric='auc')\n",
    "\n",
    "parameter_grid = {\n",
    "    'learning_rate': [0.2, 0.3, 0.5, 1.0],\n",
    "    'alpha': [0, 0.01, 0.1],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'gamma': [0, 0.01, 0.1]\n",
    "}\n",
    "\n",
    "grid_search(model, parameter_grid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
